<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="博弈论与机制设计笔记（更新中）, Frank&#39;s Blog, LDVYYC, 于雨琛, blog">
    <meta name="baidu-site-verification" content="fmlEuI34ir" />
    <meta name="google-site-verification" content="yCy2azpds5XSuGZvis6OuA-XIGF5GuGpYRAaGfD6o48" />
    <meta name="360-site-verification" content="b7c11a830ef90fd1464ad6206bb7b6e7" />
    <meta name="description" content="L2: Static Games of Complete InformationNormal-form games
Static: one shot, simultaneous move
complete information: each">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>博弈论与机制设计笔记（更新中） | Frank&#39;s Blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?ce84511d3df71640a9378a69f6293044";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

    
        <script>
            (function(){
                var bp = document.createElement('script');
                var curProtocol = window.location.protocol.split(':')[0];
                if (curProtocol === 'https') {
                    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
                }
                else {
                    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
                }
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(bp, s);
            })();
        </script>
    

    <script>
        (function(){
        var src = "https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba";
        document.write('<script src="' + src + '" id="sozz"><\/script>');
        })();
    </script>

<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Frank's Blog" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body>

    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/favicon.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Frank's Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/contact" class="waves-effect waves-light">
            
            <i class="fa fa-comments"></i>
            
            <span>留言板</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/favicon.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Frank's Blog</div>
        <div class="logo-desc">
            
            Still I Rise
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/contact" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-comments"></i>
                
                留言板
            </a>
        </li>
        
        
    </ul>
</div>

        </div>

        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230317152434.png')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        博弈论与机制设计笔记（更新中）
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                        <a href="/tags/Notes/" target="_blank">
                            <span class="chip bg-color">Notes</span>
                        </a>
                        
                        <a href="/tags/GameTheory/" target="_blank">
                            <span class="chip bg-color">GameTheory</span>
                        </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                        <a href="/categories/Learning/" class="post-category" target="_blank">
                            Learning
                        </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-03-17
                </div>

                <div class="post-author info-break-policy">
                    <i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp;
                    
                    Frank Yu
                    
                </div>

                
                
                <div class="info-break-policy">
                    <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    44 分
                </div>
                
                

                
                <div id="busuanzi_container_page_pv" class="info-break-policy">
                    <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                    <span id="busuanzi_value_page_pv"></span>
                </div>
                
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="L2-Static-Games-of-Complete-Information"><a href="#L2-Static-Games-of-Complete-Information" class="headerlink" title="L2: Static Games of Complete Information"></a>L2: Static Games of Complete Information</h2><h3 id="Normal-form-games"><a href="#Normal-form-games" class="headerlink" title="Normal-form games"></a>Normal-form games</h3><ul>
<li>Static: one shot, simultaneous move</li>
<li>complete information: each player’s payoff function is common knowledge among all players.</li>
</ul>
<h5 id="Normal-form-representation"><a href="#Normal-form-representation" class="headerlink" title="Normal-form representation"></a>Normal-form representation</h5><ul>
<li><p>the players （参与者） in the game;</p>
</li>
<li><p>the strategies （策略） available to each player;</p>
</li>
<li><p>the payoff（收益&#x2F;效用） received by each player for each combination of strategies that could be chosen by the players.</p>
</li>
<li><p>$\color{red}{\textbf{complete: 是不是common knowledge}}$</p>
</li>
<li><p>$\color{red}{\textbf{perfect: 每次decision对方是否知道}}$</p>
</li>
</ul>
<h5 id="Normal-form-Defination"><a href="#Normal-form-Defination" class="headerlink" title="Normal-form Defination"></a>Normal-form Defination</h5><p>The normal-form （标准式） （also called strategic-form） representation of an n-player game speciies the players’ strategy sets&#x2F;spaces $S_1$ , . . . , $S_n$ and their $\color{red}{\text{payoff functions}}$ u1, . . . , un. We denote this game by</p>
<ul>
<li>$$G&#x3D;&lt;S_1,S_2,…S_n,u_1,…u_n&gt;$$</li>
<li>Can also represent by bi-matrix form.</li>
</ul>
<h3 id="Concept-of-strategy"><a href="#Concept-of-strategy" class="headerlink" title="Concept of strategy"></a>Concept of strategy</h3><h4 id="Some-notations"><a href="#Some-notations" class="headerlink" title="Some notations:"></a>Some notations:</h4><ul>
<li>$$s&#x3D;(s_1,s_2,…,s_{i-1},s_i,s_{i+1},…,s_n)$$</li>
<li>$$s_{-i}&#x3D;(s_1,s_2,…,s_{i-1},s_{i+1},…,s_n)$$</li>
<li>$$S&#x3D;S_1\times S_2 \times …\times S_{i-1}\times S_{i}\times S_{i+1}\times…\times S_n$$</li>
<li>$$S_{-i}&#x3D;S_1\times S_2 \times …\times S_{i-1}\times S_{i+1}\times…\times S_n$$</li>
<li>$$\color{red}{s&#x3D;(s_i,s_{-i})}$$</li>
</ul>
<h4 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h4><ul>
<li>Best response:<ul>
<li>在其他人选定的情况下对我最有利的情况</li>
<li>$$\max_{s_i\in S_i} u_i(s_i,s_{-i})$$</li>
<li>denoted by $$R_i(s_{-i})$$</li>
</ul>
</li>
<li>Strictly dominated stratey<ul>
<li>在所有情况下都不如另一个策略，另一个策略不一定是NE</li>
<li>A rational player will never choose a strictly dominated strategy.</li>
</ul>
</li>
<li>Strictly dominant strategy<ul>
<li>在所有情况下都严格比其他所有策略好</li>
<li>If a strictly dominant strategy exists, then it must be unique. </li>
<li>A rational player will always choose a strictly dominant strategy, if any.</li>
</ul>
</li>
<li>Weakly dominant strategy<ul>
<li>在所有情况下都大于等于其他所有策略</li>
</ul>
</li>
</ul>
<h5 id="关系"><a href="#关系" class="headerlink" title="关系"></a>关系</h5><ul>
<li>A strictly dominated strategy can never be a best response</li>
<li>A strictly dominant strategy is always a best response</li>
</ul>
<h3 id="IESDS-and-Nash-Equilibrium"><a href="#IESDS-and-Nash-Equilibrium" class="headerlink" title="IESDS and Nash Equilibrium"></a>IESDS and Nash Equilibrium</h3><h4 id="IESDS"><a href="#IESDS" class="headerlink" title="IESDS"></a>IESDS</h4><ul>
<li><p>不断消去strictly dominated strategy</p>
</li>
<li><p>main drawbacks</p>
<ul>
<li>A key assumption: rationality of all players is common knowledge.</li>
<li>The prediction of IESDS may not be very precise, and sometimes it predicts nothing about the games.</li>
</ul>
</li>
</ul>
<h4 id="NE"><a href="#NE" class="headerlink" title="NE"></a>NE</h4><ul>
<li>Defination<ul>
<li>$$(s_1^*,…,s_n^*)\text{ is a NE if }s_i^*\in R_i(s_{-i}),i&#x3D;1,2,…,n$$</li>
<li>Equivalently, $$u_i(s_i^*,s_{-i}^*)&#x3D;\max_{s_i\in S_i}u_i(s_i,s_{-i}^*)$$</li>
</ul>
</li>
<li>Each player’s strategy must be a best response, given other players’ equilibrium strategies.</li>
<li>No single player wants to deviate unilaterally <ul>
<li>strategically stable or self-enforcing.</li>
</ul>
</li>
</ul>
<h5 id="Issues-on-NE"><a href="#Issues-on-NE" class="headerlink" title="Issues on NE"></a>Issues on NE</h5><ul>
<li>A Nash equilibrium needs not to be Pareto optimal （帕累托最优）</li>
<li>More generally, Nash equilibrium does not rule out the possibility that a subset of players can deviate jointly in a way that makes every player in the subset better off.</li>
<li>The Nash equilibrium <strong>implicitly assumes that players know that each player is to play the equilibrium strategy.</strong> Given this knowledge, no player wants to deviate.</li>
</ul>
<h4 id="Relationship-between-IESDS-and-NE"><a href="#Relationship-between-IESDS-and-NE" class="headerlink" title="Relationship between IESDS and NE"></a>Relationship between IESDS and NE</h4><ul>
<li>NE can survive IESDS<ul>
<li>$${\text{Nash Equilibria}\subset\text{subset of IESDS}}$$</li>
</ul>
</li>
<li>Nash equilibrium is a stronger solution concept than IESDS. </li>
<li>Nash equilibrium does not require that rationality is common knowledge.</li>
<li>在有限的情况，IESDS如果消到只剩下一个，那一定是NE</li>
</ul>
<h3 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h3><h4 id="Cournot-Duopoly"><a href="#Cournot-Duopoly" class="headerlink" title="Cournot Duopoly"></a>Cournot Duopoly</h4><ul>
<li>题目<ul>
<li>Suppose two firms （1 and 2） produce a homogeneous good, and compete in quantities.</li>
<li>Let $q_i$ be the quantity produced by firm i, where i &#x3D; 1 , 2. </li>
<li>The aggregate quantity of the good is denoted by $Q &#x3D; q_1 + q_2$. The inverse demand （反需求函数） of the good is $P(Q)&#x3D;a-Q$ </li>
<li>The cost function of firm i is $C_i(q_i) &#x3D; cq_i$</li>
</ul>
</li>
<li>将题目化成 normal-form game</li>
<li>找best response 的交点</li>
<li>结论：</li>
<li>$$(q_1^*,q_2^*)&#x3D;(\frac{1}{3}(a-c),\frac{1}{3}(a-c))$$</li>
</ul>
<h4 id="Bertrand-Model-of-Duopoly"><a href="#Bertrand-Model-of-Duopoly" class="headerlink" title="Bertrand Model of Duopoly"></a>Bertrand Model of Duopoly</h4><ul>
<li>计算过程类似 cournot</li>
</ul>
<h3 id="Mixed-strategies"><a href="#Mixed-strategies" class="headerlink" title="Mixed strategies"></a>Mixed strategies</h3><h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><ul>
<li>In a normal-form game $G&#x3D;\left\langle S_1, \ldots, S_n ; u_1, \ldots, u_n\right\rangle$, suppose $S_i&#x3D;{s_{i1}, …, s_{iK_i}}$<ul>
<li>Each strategy $s_{i k} \in S_i$ is a pure strategy (纯策略) for player</li>
<li>A mixed strategy (混合策略) for player $i$ is a probability distribution $p_i&#x3D;\left(p_{i 1}, \ldots, p_{i K_i}\right)$, for $k&#x3D;1, \ldots, K_i$, where $p_{i 1}+\cdots+p_{i K_i}&#x3D;1$ and $p_{i k} \geq 0$.</li>
</ul>
</li>
</ul>
<ul>
<li>Note that there are only $K_i$ pure strategies for player $i$, but infinitely many mixed strategies.</li>
</ul>
<h4 id="Expected-payoff"><a href="#Expected-payoff" class="headerlink" title="Expected payoff"></a>Expected payoff</h4><ul>
<li>If player 1 thinks that player 2 will play a mixed strategy $p_2&#x3D;\left(p_{21}, \ldots, p_{2 K}\right)$, then player 1’s expected payoff （期望效用） of playing a pure strategy $s_{1 j}$ is</li>
<li>$$v_1\left(s_{1 j}, p_2\right)&#x3D;\sum_{k&#x3D;1}^K p_{2 k} u_1\left(s_{1 j}, s_{2 k}\right) .$$</li>
<li>Player 1’s expected payoff （期望效用） of playing a mixed strategy $p_1&#x3D;\left(p_{11}, \ldots, p_{1 J}\right)$ is</li>
<li>$$\begin{aligned}<br>v_1\left(p_1, p_2\right) &amp; &#x3D;\sum_{j&#x3D;1}^J p_{1 j} \sum_{k&#x3D;1}^K p_{2 k} u_1\left(s_{1 j}, s_{2 k}\right) \<br>&amp; &#x3D;\sum_{j&#x3D;1}^J \sum_{k&#x3D;1}^K p_{1 j} p_{2 k} u_1\left(s_{1 j}, s_{2 k}\right)<br>\end{aligned}$$</li>
</ul>
<ul>
<li><strong>A mixed strategy $p_1 &#x3D; (p_{11} , . . . , p_{1j})$ is a best response （最优应对） to $p_2$ if</strong><ul>
<li>$$v_1(p_1,p_2)\geq v_1(p_1^\prime,p_2)$$</li>
</ul>
</li>
</ul>
<h4 id="Mixed-strategy-NE"><a href="#Mixed-strategy-NE" class="headerlink" title="Mixed strategy NE"></a>Mixed strategy NE</h4><h5 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h5><ul>
<li><p>In a normal-form game $G&#x3D;\left\langle S_1, \ldots, S_n ; u_1, \ldots, u_n\right\rangle$, the mixed strategy profile $\left(p_1^*, \ldots, p_n^*\right)$ is a mixed-strategy Nash equilibrium if each player’s mixed strategy is a best response to the other players’ mixed strategies in terms of expected payoff, i.e.,</p>
</li>
<li><p>$$v_(p_i^*, p_{-i}^*)\geq v_i(p_i, p_{-i}^*)$$</p>
</li>
<li><p>for every $p_i$ over $S_i$, and for all $i&#x3D;1, \ldots, n$.</p>
</li>
<li><p>求解：</p>
<ul>
<li><strong>mixed strategy 必须每个分量都是indifferent，每个选项的预期收益是相同的</strong></li>
</ul>
</li>
</ul>
<h5 id="Applications-1"><a href="#Applications-1" class="headerlink" title="Applications"></a>Applications</h5><ul>
<li><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230403211543.png" alt="matching pennies"></li>
<li><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230403211350.png" alt="matching pennies solution"></li>
<li><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230403211612.png" alt="battle of sexes"></li>
<li><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230403211452.png" alt="battle of sexes solution"></li>
</ul>
<h5 id="proposition"><a href="#proposition" class="headerlink" title="proposition"></a>proposition</h5><ul>
<li>The pure strategies played with a positive probability in a mixed strategy Nash equilibrium survive IESDS.</li>
<li>A pure strategy is a strictly dominated strategy （dominated by a mixed strategy） if and only if it is never a best response （to mixed strategies）.<ul>
<li>考虑有mixed strategy情况下</li>
<li>充要条件</li>
<li>即如果有某些action的组合比该action的收益严格高，那么该action就不可能是best response。</li>
</ul>
</li>
</ul>
<h4 id="存在性定理"><a href="#存在性定理" class="headerlink" title="存在性定理"></a>存在性定理</h4><ul>
<li>定理：<ul>
<li>In the n-player normal-form game $G &#x3D; ⟨S_1 , . . . , S_n; u_1, . . . , u_n⟩$, if n is finite and $S_i$ is finite for every i, then there exists at least one Nash equilibrium, possibly involving mixed strategies.</li>
</ul>
</li>
<li>The conditions are suicient but not necessary conditions for the existence of a Nash equilibrium. <ul>
<li>充分不必要条件</li>
</ul>
</li>
<li>Recall that in both Cournot and Betrand competition models, Nash equilibrium exists but the strategy space is infinite.</li>
</ul>
<hr>
<h2 id="L3-Dynamic-Games-of-Complete-Information"><a href="#L3-Dynamic-Games-of-Complete-Information" class="headerlink" title="L3: Dynamic Games of Complete Information"></a>L3: Dynamic Games of Complete Information</h2><h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><ul>
<li><p>dynamic games: sequential choice or repeated play</p>
</li>
<li><p>Complete Information:  each player’s payoff function is common knowledge among all players </p>
</li>
<li><p><strong>center issue is credibility.</strong></p>
</li>
<li><p>Use  extensive-form （扩展式） representation for dynamic games. </p>
</li>
<li><p>Draw game trees.</p>
</li>
</ul>
<h3 id="Games-of-Perfect-Information"><a href="#Games-of-Perfect-Information" class="headerlink" title="Games of Perfect Information"></a>Games of Perfect Information</h3><p><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316092735.png" alt="example of dynamic games of complete and perfect information"></p>
<p>Player 2 choose after he knows what player 1 choose.</p>
<p>If its imperfect Information, we draw a dotted line between 2 and 2 in the tree above.</p>
<p><strong>Note that</strong></p>
<ul>
<li>$A_2$ may depend on the action a1, i.e., $A_2(a_1)$.</li>
<li>Some action $a_1$ may even end the game, so that $A_2(a_1)$ is an empty set （i.e., no choice of player 2）.</li>
<li>The action $a_1$ is perfectly observed by player 2.</li>
</ul>
<p>In the game of the farmer and the snake:<br><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316093517.png" alt="农夫与蛇"></p>
<h5 id="Some-key-features"><a href="#Some-key-features" class="headerlink" title="Some key features"></a>Some key features</h5><ul>
<li>the moves occur in sequence;</li>
<li>all previous moves are observed before the next move ischosen</li>
<li>the players’ payoffs from each combination of moves are common knowledge.</li>
</ul>
<h4 id="Backwards-Induction"><a href="#Backwards-Induction" class="headerlink" title="Backwards Induction"></a>Backwards Induction</h4><ul>
<li>In the second stage, player 2 observes what player 1 choose and choose action to solving $$\max \limits_{a_2\in A_2}\quad u_2(a_1, a_2)$$</li>
<li>Assume this optimization problem has a unique solution, denoted by $R_2(a_1)$.<ul>
<li>This is player 2’s best response to player 1’s action $a_1$</li>
</ul>
</li>
<li>In the first stage, knowing player 2’s best response, player 1’s problem become$$\max \limits_{a_1\in A_1}\quad u_1(a_1, R_2(a_1))$$</li>
<li>Assume it also has a unique solution, denoted by $a_1^*$.</li>
<li>We call $(a_1, R_2(a_1^*))$ the backwards-induction outcome (逆向归纳的结果) of the game</li>
<li>In the backwards-induction outcome, $a_1^*$ is determined by maximizing $u_1 (a_1 , R_2(a_1))$, and $a_2^* &#x3D; R_2(a_1^*)$. </li>
<li>However, $a_1^*$ may not maximize $u_1(a_1, a_2^*)$.<br><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316101111.png" alt="image.png"></li>
</ul>
<h4 id="Stackelberg-Model-of-Duopoly"><a href="#Stackelberg-Model-of-Duopoly" class="headerlink" title="Stackelberg Model of Duopoly"></a>Stackelberg Model of Duopoly</h4><p>Consider a dominant firm moving first and a follower moving second.</p>
<ul>
<li>The game is as follows:<ul>
<li>Firm 1 choose quantity $q_1 \ge 0$<ul>
<li>Firm 2 observes $q_1$ and then chooses a quantity $q_2 \ge 0$.</li>
</ul>
</li>
<li>The payoff of firm i is the profit $$\pi_i\left(q_1, q_2\right)&#x3D;q_i[P(Q)-c]$$</li>
<li>where $Q&#x3D;q_1+q_2$ and<br>$$<br>P(Q)&#x3D; \begin{cases}a-Q, &amp; \text { if } Q&lt;a \\ 0, &amp; \text { if } Q \geq a\end{cases}<br>$$</li>
</ul>
</li>
</ul>
<h5 id="Now-solve-this-game"><a href="#Now-solve-this-game" class="headerlink" title="Now solve this game."></a>Now solve this game.</h5><ul>
<li>First, find the best response function $R_2 (q_1)$ for firm 2, i.e.for any given $q_1$, find $q_2$ that solves $$\max _{q_2 \geq 0} \pi_2\left(q_1, q_2\right)$$where<br>$$\pi_2\left(q_1, q_2\right)&#x3D; \begin{cases}q_2\left(a-q_1-q_2-c\right), &amp; \text { if } q_1+q_2&lt;a ; \\ -c q_2, &amp; \text { if } q_1+q_2 \geq a .\end{cases}$$ </li>
<li>Then we have<br>$$<br>R_2\left(q_1\right)&#x3D; \begin{cases}\frac{a-c-q_1}{2}, &amp; \text { if } q_1&lt;a-c \\ 0, &amp; \text { if } q_1 \geq a-c .\end{cases}<br>$$</li>
<li>$R_2(q_1)$ is the same as that in the Cournot model.</li>
<li>Second, firm 1 knows $R_2 (q_1)$ and solves$$\max \limits_{q_1 \ge 0} \quad \pi_1(q_1, R_2(q_1))$$ where$$\pi_1\left(q_1, R_2\left(q_1\right)\right)&#x3D; \begin{cases}q_1\left[a-q_1-\frac{a-q_1-c}{2}-c\right], &amp; \text { if } q_1&lt;a-c \\ q_1\left[a-q_1-c\right], &amp; \text { if } a-c \leq q_1&lt;a \\ -c q_1, &amp; \text { if } q_1 \geq a\end{cases}$$</li>
</ul>
<ul>
<li>Clearly, for $q_1&gt;a-c$, firm 1’s profit is always negative.</li>
<li>Thus we only need to solve<br>$$<br>\max _{a-c \geq q_1 \geq 0} q_1\left[a-q_1-\frac{a-q_1-c}{2}-c\right],<br>$$<br>which leads to the following first-order condition<br>$$<br>a-c-2 q_1&#x3D;0 .<br>$$</li>
<li>The optimal choice of firm 1 is<br>$$<br>q_1^*&#x3D;\frac{a-c}{2}<br>$$</li>
<li>The quantity chosen by firm 2 is<br>$$<br>q_2^*&#x3D;R_2\left(q_1^*\right)&#x3D;\frac{a-c}{4} .<br>$$</li>
<li>The market price is<br>$$<br>P^*&#x3D;a-q_1^*-q_2^*&#x3D;c+\frac{a-c}{4} .<br>$$</li>
<li>Firms’ profits and the total profit are<br>$$<br>\pi_1^*&#x3D;\frac{(a-c)^2}{8}, \pi_2^*&#x3D;\frac{(a-c)^2}{16}, \text { and } \Pi^*&#x3D;\frac{3(a-c)^2}{16}<br>$$</li>
</ul>
<h5 id="Compare-with-Cournot-Model"><a href="#Compare-with-Cournot-Model" class="headerlink" title="Compare with Cournot Model"></a>Compare with Cournot Model</h5><p>$$<br>\begin{aligned}<br>&amp;\begin{array}{ccc}<br>\text {Variable} &amp; \text{Cournot Model} &amp; \text{Stackelberg Model}\\<br>\hline q_1^* &amp; \frac{a-c}{3} &amp; \frac{a-c}{2} \\<br>q_2^* &amp; \frac{a-c}{3} &amp; \frac{a-c}{4} \\<br>\pi_1^* &amp; \frac{(a-c)^2}{9} &amp; \frac{(a-c)^2}{8} \\<br>\pi_2^* &amp; \frac{(a-c)^2}{9} &amp; \frac{(a-c)^2}{16} \\<br>\Pi^* &amp; \frac{2(a-c)^2}{9} &amp; \frac{3(a-c)^2}{16} \\<br>P^* &amp; c+\frac{a-c}{3} &amp; c+\frac{a-c}{4} \\<br>\hline<br>\end{array}<br>\end{aligned}<br>$$</p>
<ul>
<li>Note: First-move advantage:<ul>
<li>先手有优势，比起同时的情况。</li>
</ul>
</li>
</ul>
<h3 id="Games-of-Imperfect-Information"><a href="#Games-of-Imperfect-Information" class="headerlink" title="Games of Imperfect Information"></a>Games of Imperfect Information</h3><ul>
<li>Consider the following game<ul>
<li>Players 1 and 2 simultaneously choose actions $a_1$ and $a_2$ from the feasible sets $A_1$ and $A_2$, respectively.</li>
<li>Players 3 and 4 observe the outcome of the first stage $(a_1 , a_2)$ and then simultaneously choose actions $a_3$ and $a_4$ from the feasible sets $A_3$ and $A_4$, respectively.</li>
<li>Payoffs are $u_i(a_1, a_2, a_3, a_4)$ for i &#x3D; 1, 2, 3, 4.</li>
</ul>
</li>
<li><strong>There are simultaneous moves within each stage.</strong></li>
</ul>
<h5 id="Solve"><a href="#Solve" class="headerlink" title="Solve"></a>Solve</h5><ul>
<li>Still, backwards induction.</li>
</ul>
<ul>
<li>For each given $\left(a_1, a_2\right)$, players 3 and 4 try to find the Nash equilibrium in stage 2.</li>
<li>Assume the second-stage game has a unique Nash equilibrium$(a_3^*(a_1, a_2), a_4^*(a_1, a_2))$$</li>
<li>Then, player 1 and player 2 play a simultaneous-move game with payoffs$$<br>u_i(a_1, a_2, a_3^*(a_1, a_2), a_4^*(a_1, a_2)), \text { for } i&#x3D;1,2$$</li>
<li>Suppose $(a_1^*, a_2^*)$ is the unique Nash equilibrium of this simultaneous-move game.</li>
<li>Then$$(a_1^*, a_2^*, a_3^*(a_1^*, a_2^*), a_4^*(a_1^*, a_2^*))$$is the subgame-perfect outcome （子博恋精炼结果） of the two-stage game.</li>
</ul>
<h5 id="Example-Bank-Run"><a href="#Example-Bank-Run" class="headerlink" title="Example: Bank Run"></a>Example: Bank Run</h5><ul>
<li>payoff in date 1:</li>
<li><table>
<thead>
<tr>
<th></th>
<th>Withdraw</th>
<th>Don’t</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Withdraw</strong></td>
<td>4,4</td>
<td>5,3</td>
</tr>
<tr>
<td><strong>Don’t</strong></td>
<td>3,5</td>
<td>next stage</td>
</tr>
</tbody></table>
</li>
<li>payoff in date 2</li>
<li><table>
<thead>
<tr>
<th></th>
<th>Withdraw</th>
<th>Don’t</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Withdraw</strong></td>
<td>8,8</td>
<td>11,5</td>
</tr>
<tr>
<td><strong>Don’t</strong></td>
<td>5,11</td>
<td>8,8</td>
</tr>
</tbody></table>
</li>
</ul>
<h6 id="Solve-backwards"><a href="#Solve-backwards" class="headerlink" title="Solve: backwards"></a>Solve: backwards</h6><ul>
<li>date2, both obtain 8 in nash equilibrium.</li>
<li>Thus, in date1, they play the following game:</li>
<li><table>
<thead>
<tr>
<th></th>
<th>Withdraw</th>
<th>Don’t</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Withdraw</strong></td>
<td>4,4</td>
<td>5,3</td>
</tr>
<tr>
<td><strong>Don’t</strong></td>
<td>3,5</td>
<td>8,8</td>
</tr>
</tbody></table>
</li>
</ul>
<p>There are two NE.</p>
<h3 id="Extensive-form-Representation"><a href="#Extensive-form-Representation" class="headerlink" title="Extensive-form Representation"></a>Extensive-form Representation</h3><h5 id="Defination"><a href="#Defination" class="headerlink" title="Defination"></a>Defination</h5><p>The extensive-form (扩展式) representation of a game specifies:</p>
<ul>
<li>the players in the game;</li>
<li>when each player has the move; *</li>
<li>what each player can do at each of his or her opportunities to move; *</li>
<li>what each player knows at each of his or her opportunities to move; *</li>
<li>the payoffs received by each player for each combination of moves that could be chosen by the players<br><strong>the three * part describes strategies of each player in detail.</strong></li>
</ul>
<p>use trees for extensive-form representations.<br><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316110447.png" alt="extensive-form representation"></p>
<h4 id="Information-Set"><a href="#Information-Set" class="headerlink" title="Information Set"></a>Information Set</h4><ul>
<li>Complete and perfect information<ul>
<li>A dynamic game of complete and perfect information is a game in which the players move in sequence, all previous moves are observed before the next move is chosen, and payoffs are common knowledge. </li>
<li><strong>Such games can be easily represented by a game tree.</strong></li>
</ul>
</li>
<li>Imperfect information<ul>
<li>some previous moves are not observed by the player with the current move. </li>
<li>To present this kind of ignorance of previous moves and to describe what each player knows at each of his&#x2F;her move, we introduce the notion of a player’s information set （信息集）</li>
</ul>
</li>
</ul>
<h5 id="Definition-of-Information-Set"><a href="#Definition-of-Information-Set" class="headerlink" title="Definition of Information Set"></a>Definition of Information Set</h5><p>An information set （信息集） for a player is a collection of decision nodes satisfying:</p>
<ul>
<li>The player needs to move at every node in the information set.</li>
<li>When the play of the game reaches a node in the information set, the player with the move does not know which node in the set has （or has not） been reached.<ul>
<li>implies that the player must have the same set of feasible actions at each decision node in an information set; Otherwise the player could infer from the set of actions available that some nodes had or had not been reached.</li>
</ul>
</li>
<li><strong>Any two nodes from different information sets of a player can be distinguished from each other.</strong></li>
</ul>
<h5 id="Application-of-Information-Set"><a href="#Application-of-Information-Set" class="headerlink" title="Application of Information Set"></a>Application of Information Set</h5><ul>
<li>A game is:<ul>
<li>of perfect information （完美信息） if every information set is a singleton;</li>
<li>of imperfect information （不完美信息） if there is at least one non-singleton information set.<ul>
<li>meaning there is at least a dotted line in the tree form.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Prisoners Dilemma<br><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316113717.png" alt="prisoners dilemma"></p>
<h4 id="Strategy"><a href="#Strategy" class="headerlink" title="Strategy"></a>Strategy</h4><h5 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition"></a>Definition</h5><p>A strategy (策略) for a player is a complete plan of actions. It specifies a feasible action for the player in every contingency in which the player might be called on to act.</p>
<ul>
<li>For dynamic games with complete information: <ul>
<li>A player’s strategy is a function which assigns an action to each information set (not each decision node) belonging to the player. </li>
<li>对每个选择节点，指定一个策略</li>
</ul>
</li>
<li>An action and a strategy do not make a big diference in static games, while they do in dynamic games.</li>
</ul>
<h5 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h5><p><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316111235.png" alt="example"></p>
<ul>
<li>Player 1 has 2 actions (and also 2 strategies): L and R. Player 2 has 2 actions: L′ and R′, but 4 strategies:$$(L^\prime, L^\prime); (L^\prime, R^\prime); (R^\prime, L^\prime); (R^\prime, R^\prime)$$</li>
<li>For example, the strategy $(L^\prime, R^\prime)$ means:<ul>
<li>if player 1 plays L, then player 2 plays $L^\prime$;</li>
<li>if player 1 plays R, then player 2 plays $R^\prime$.</li>
</ul>
</li>
</ul>
<h3 id="Subgame-perfect-Nash-Equilibrium"><a href="#Subgame-perfect-Nash-Equilibrium" class="headerlink" title="Subgame-perfect Nash Equilibrium"></a>Subgame-perfect Nash Equilibrium</h3><h5 id="Question-how-to-represent-this-game-in-normal-form"><a href="#Question-how-to-represent-this-game-in-normal-form" class="headerlink" title="Question: how to represent this game in normal form?"></a>Question: how to represent this game in normal form?</h5><p><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316111235.png" alt="same game"></p>
<ul>
<li><table>
<thead>
<tr>
<th></th>
<th>$L^\prime L^\prime$</th>
<th>$L^\prime R^\prime$</th>
<th>$L^\prime L^\prime$</th>
<th>$L^\prime L^\prime$</th>
</tr>
</thead>
<tbody><tr>
<td><strong>L</strong></td>
<td>3,1</td>
<td>3,1</td>
<td>1,2</td>
<td>1,2</td>
</tr>
<tr>
<td><strong>R</strong></td>
<td>2,1</td>
<td>0,0</td>
<td>2,1</td>
<td>0,0</td>
</tr>
</tbody></table>
</li>
<li>there are two NE: $(L, R^\prime R^\prime)$, $(R, R^\prime L^\prime)$</li>
</ul>
<h5 id="Interpret"><a href="#Interpret" class="headerlink" title="Interpret"></a>Interpret</h5><ul>
<li>NE $(R, R^\prime L^\prime)$ seems okay. It respects the spirit of backwards induction.</li>
<li>NE $(L, R^\prime R^\prime)$ has a problem: No matter which action is chosen by Player 1, player 2 must choose L′ at the right node. </li>
<li><strong>Interpretation: Player 2 tells player 1: if you choose R, I will choose R′ （threat）, then each of us will get 0.</strong> </li>
<li>This threat is non-creditable: Player 1 should not believe that player 2 will choose R′ after observing R. </li>
<li>Key: Ignorance of dynamic feature.</li>
</ul>
<h4 id="Subgame"><a href="#Subgame" class="headerlink" title="Subgame"></a>Subgame</h4><h6 id="Defination-1"><a href="#Defination-1" class="headerlink" title="Defination"></a>Defination</h6><ul>
<li><p>A subgame (子博弈) in an extensive-form game</p>
<ul>
<li>begins at a decision node n that is a singleton information set （but is not the game’s initial node）; </li>
<li>includes all the decision and terminal nodes following node n in the game tree （but no nodes that do not follow n）; </li>
<li>does not cut any information sets （i.e., if a decision node n′ follows n in the game tree, then all other nodes in the information set containing n′ must also follow n, and so must be included in the subgame）.</li>
<li><strong>只能从一个singleton的decision node节点切出来，并且不能把任何information set切断</strong></li>
</ul>
</li>
<li><p>When focus on a subgame, we shall only consider the relevant part of the strategy profile s. </p>
</li>
<li><p>Relevant part of s specifies the “complete” plans （or strategy profile） for the players in that subgame.</p>
</li>
</ul>
<h6 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h6><p><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230317150643.png" alt="example"></p>
<ul>
<li>We have a strategy profile $\left(L,\left(L^{\prime}, R^{\prime}\right),\left(L^{\prime \prime}, R^{\prime \prime}, R^{\prime \prime}, L^{\prime \prime}\right)\right)$.</li>
<li>We turn to the subgame beginning at player 2’s right decision node.</li>
<li>The relevant part is $\left(R^{\prime},\left(R^{\prime \prime}, L^{\prime \prime}\right)\right)$ or $\left(-, R^{\prime},\left(R^{\prime \prime}, L^{\prime \prime}\right)\right)$. It is a strategy profile for this subgame.<ul>
<li>We can discuss whether it is “reasonable”, within this subgame.</li>
</ul>
</li>
<li>One can repeat this procedure for every subgame.</li>
</ul>
<h3 id="Subgame-Perfect-Nash-Equilibrium"><a href="#Subgame-Perfect-Nash-Equilibrium" class="headerlink" title="Subgame-Perfect Nash Equilibrium"></a>Subgame-Perfect Nash Equilibrium</h3><h5 id="Definition-3"><a href="#Definition-3" class="headerlink" title="Definition"></a>Definition</h5><p>A Nash equilibrium is subgame-perfect (子博弈精炼), or is said to be a subgame-perfect Nash equilibrium (子博弈精炼均衡) if the players’ strategies constitute a Nash equilibrium in every subgame.</p>
<h5 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h5><ul>
<li>It can be shown that any finite dynamic game of complete information has a subgame-perfect Nash equilibrium, perhaps in mixed-strategies. </li>
<li>To find subgame-perfect Nash equilibria, <ul>
<li>we first need to find Nash equilibria in each subgame,</li>
<li>then use backwards-induction to solve for the whole game</li>
</ul>
</li>
<li>Subgame-perfect Nash equilibrium is closely related to two previous concepts:<ul>
<li>1 backwards-induction outcome;</li>
<li>2 subgame-perfect outcome. </li>
<li>两者仅存在术语的差别，没有什么本质区别；混用没有问题。</li>
</ul>
</li>
<li>What’s the diference between an equilibrium and an outcome? <ul>
<li><strong>An equilibrium is a collection of players’ strategies (strategy profile), while an outcome is a collection of players’ actions.</strong></li>
</ul>
</li>
</ul>
<h5 id="Equilibrium-vs-Outcome"><a href="#Equilibrium-vs-Outcome" class="headerlink" title="Equilibrium vs. Outcome"></a>Equilibrium vs. Outcome</h5><ul>
<li>Example：<ul>
<li>The backwards-induction outcome is $\left(a_1^*, R_2\left(a_1^*\right)\right)$.</li>
<li>The subgame-perfect Nash equilibrium is $\left(a_1^*, R_2(\cdot)\right)$.</li>
<li>Note that $R_2\left(a_1^*\right)$ is an action, while $R_2(\cdot)$ is a strategy for player 2.</li>
</ul>
</li>
</ul>
<ul>
<li>In Example 1:<ul>
<li>$\left(R, L^{\prime}\right)$ is the backwards-induction outcome,</li>
<li>while $\left(R,\left(R^{\prime}, L^{\prime}\right)\right)$ is the subgame-perfect Nash equilibrium.</li>
</ul>
</li>
<li>In the Stackelberg model:<ul>
<li>The backwards-induction outcome is $\left(q_1^*, q_2^<em>\right)$, where $q_1^</em>&#x3D;\frac{a-c}{2}$ and $q_2^*&#x3D;\frac{a-c}{4}$,</li>
<li>while the subgame-perfect Nash equilibrium is $\left(q_1^*, R_2\left(q_1\right)\right)$, where $R_2\left(q_1\right)&#x3D;\frac{a-c-q_1}{2}$.</li>
</ul>
</li>
<li>For the two-stage game of complete but imperfect information<ul>
<li>Then the subgame-perfect outcome is<br>$$(a_1^*, a_2^*, a_3^*(a_1^*, a_2^*), a_4^*(a_1^*, a_2^*)) .<br>$$</li>
</ul>
<ul>
<li>The subgame-perfect Nash equilibrium is$$(a_1^*, a_2^*, a_3^*(a_1, a_2), a_4^*(a_1, a_2)) .$$</li>
</ul>
</li>
</ul>
<h5 id="Nash-Equilibrium-vs-Subgame-Perfect-Nash-Equilibrium"><a href="#Nash-Equilibrium-vs-Subgame-Perfect-Nash-Equilibrium" class="headerlink" title="Nash Equilibrium vs. Subgame-Perfect Nash Equilibrium"></a>Nash Equilibrium vs. Subgame-Perfect Nash Equilibrium</h5><p><strong>A Nash equilibrium may not be subgame-perfect.</strong></p>
<ul>
<li>Following the example above.<ul>
<li>The Nash equilibrium $\left(R,\left(R^{\prime}, L^{\prime}\right)\right)$ is subgame-perfect, because $R^{\prime}$ and $L^{\prime}$ are the optimal strategies in the left and right subgames, respectively, where player 2 is the only player.</li>
<li>On the other hand, the Nash equilibrium $\left(L,\left(R^{\prime}, R^{\prime}\right)\right)$ is not subgame-perfect, because when player 1 chooses $R, R^{\prime}$ is not optimal to player 2 in the right subgame, i.e., $R^{\prime}$ is not a Nash equilibrium in that subgame.</li>
<li>One can think the strategy $\left(R^{\prime}, R^{\prime}\right)$ by player 2 as a threat to player 1.</li>
</ul>
</li>
</ul>
<ul>
<li>Nash equilibria that rely on non-credible threats or promises can be eliminated by the requirement of subgame perfection.</li>
<li>Subgame-perfect Nash equilibrium is a refinement of Nash equilibrium, i.e.,<br>  ${ \text{Subgame-perfect Nash equilibria} } \subseteq{ \text{Nash equilibria} }$</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>We have considered dynamic games of complete information.</li>
<li>Two basic questions:<ul>
<li>How to describe a dynamic situation $\rightarrow$ extensive-form representation.</li>
<li>How to solve a dynamic game? Why to introduce SPNE?</li>
</ul>
</li>
<li>Backwards induction vs. SPNE.</li>
<li>静态场景 $\rightarrow$ 静态模型 $\rightarrow$ 标准式<ul>
<li>静态场景 $\rightarrow$ 动态模型 （带有不完美信息） $\rightarrow$ 扩展式 （没有失去场景的特点）</li>
</ul>
</li>
<li>动态场景 $\rightarrow$ 动态模型 $\rightarrow$ 扩展式<ul>
<li>动态场景 $\rightarrow$ 静态模型 $\rightarrow$ 标准式 （失去场景的动态特点）</li>
</ul>
</li>
</ul>
<hr>
<h2 id="L4-Repeated-games"><a href="#L4-Repeated-games" class="headerlink" title="L4:Repeated games"></a>L4:Repeated games</h2><ul>
<li>In a long-term relationship, one must consider how his&#x2F;her current behavior will influence others’ behavior in the future, or how threats or promises about future behavior can afect current behavior. </li>
<li>In these dynamic situations, one might care about “reputation”, which is often used to describe how a person’s past actions affect future beliefs and behavior.</li>
</ul>
<h3 id="Finitely-repeated-games"><a href="#Finitely-repeated-games" class="headerlink" title="Finitely repeated games"></a>Finitely repeated games</h3><ul>
<li>The payoff of each player in the whole game is simply the sum of two payoffs in both stages （i.e., no discounting）.</li>
</ul>
<h4 id="Definition-4"><a href="#Definition-4" class="headerlink" title="Definition"></a>Definition</h4><ul>
<li>Let $G &#x3D; ⟨A1 , . . . , An; u1, . . . , un⟩$ denote a static game of complete information in which players 1 through n simultaneously choose actions $a_1$ through an from the action spaces $A_1$ through $A_n$, and the payoffs are $u_1(a_1, . . . , a_n)$ through $u_n(a_1, . . . , a_n)$.</li>
<li>The game G is called the stage game （阶段博弈） of the repeated game.</li>
<li>Given a stage game G, let $G(T)$ denote the finitely repeated game in which G is played T times, with the outcomes of all preceding plays observed before the next play begins. The payoffs for $G(T)$ are simply the sum of the payoffs from the T stage games.</li>
</ul>
<h4 id="Proposition"><a href="#Proposition" class="headerlink" title="Proposition"></a>Proposition</h4><ul>
<li>If the stage game G has a unique Nash equilibrium, then for any finite T, the repeated game $G(T)$ has a unique subgame-perfect outcome: the Nash equilibrium of G is played in every stage.</li>
<li>if the stage game G has multiple Nash equilibria:<ul>
<li>there may be subgame-perfect outcomes of the repeated game $G(T)$ in which, for any t &lt; T, the outcome of stage t is not a Nash equilibrium of G.</li>
<li>可以达到整体的更优化，因为可以用差的NE作为威胁。</li>
</ul>
</li>
</ul>
<h3 id="Infinitely-repeated-games"><a href="#Infinitely-repeated-games" class="headerlink" title="Infinitely repeated games"></a>Infinitely repeated games</h3><h4 id="Definition-5"><a href="#Definition-5" class="headerlink" title="Definition"></a>Definition</h4><ul>
<li>Given a stage game G, let $G(∞, δ)$ denote the ininitely repeated game in which G is played forever and players share the discount factor $δ$.</li>
<li>For each t, the outcomes of the t − 1 preceding plays are observed before the t-th stage begins. </li>
<li>Each player’s payoff in $G(∞, δ)$ is the present value of the player’s payoffs from the infinite sequence of stage games.</li>
</ul>
<h4 id="Strategies"><a href="#Strategies" class="headerlink" title="Strategies"></a>Strategies</h4><ul>
<li>noncooperative strategy:<ul>
<li>play one choice in every stage.</li>
</ul>
</li>
<li>（grim） trigger strategy （触发策略）: <ul>
<li>play A in the first stage; in stage t, if the outcome of all t − 1 preceding stages has been the binding choice, then play A; otherwise, play B.</li>
</ul>
</li>
<li>tit-for-tat （or tit for two tats） strategy （以牙还牙策略）</li>
<li>carrot-and-stick strategy （or two-phase strategy） （胡萝卜加大棒策略）</li>
</ul>
<h4 id="Nash-Equilibria"><a href="#Nash-Equilibria" class="headerlink" title="Nash Equilibria"></a>Nash Equilibria</h4><ul>
<li>需要证明所有偏离的策略收益都不如现在的选择。</li>
</ul>
<h4 id="Subgame-perfect-Nash-Equilibria"><a href="#Subgame-perfect-Nash-Equilibria" class="headerlink" title="Subgame-perfect Nash Equilibria"></a>Subgame-perfect Nash Equilibria</h4><ul>
<li><p>In an infinitely repeated game, a subgame is characterized by its previous history. The subgames can be grouped as follows:</p>
<ul>
<li>Subgames whose previous histories are always a finite sequence of binding choice. <ul>
<li>此时，判断是否要deviate。</li>
</ul>
</li>
<li>Subgames whose previous histories contain other outcomes different from the binding choice.<ul>
<li>此时，选择NE是均衡</li>
</ul>
</li>
</ul>
</li>
<li><p>需要证明在每一个情况都是NE</p>
</li>
<li><p>$\color{red}{\text{One-deviation principle (单阶段偏离原则)}}$ </p>
<ul>
<li>A strategy profile is a subgame-perfect Nash equilibrium if and only if, for each player i and for each subgame, no single deviation would raise player i’s payoff in the subgame.</li>
</ul>
</li>
</ul>
<h5 id="Two-phase-strategy-SPNE"><a href="#Two-phase-strategy-SPNE" class="headerlink" title="Two-phase strategy SPNE"></a>Two-phase strategy SPNE</h5><ul>
<li>胡萝卜加大棒策略</li>
<li>in the first period, produce half of the monopoly quantity $q_m&#x2F;2$. In period t, produce $q_m&#x2F;2$ if both firms produce $q_m&#x2F;2$ or both firms produce x in period t − 1; otherwise, produce x. </li>
<li>This strategy involve a （one-period） punishment phase in which the firm produces x and a （potentially infinite） collusive phase in which the firm produces $q_m&#x2F;2$</li>
<li>Such a strategy punishes<ul>
<li>a firm for deviating from the collusive phase;</li>
<li>a firm for deviating from the punishment phase.</li>
</ul>
</li>
</ul>
<h4 id="Folk-theorem"><a href="#Folk-theorem" class="headerlink" title="Folk theorem"></a>Folk theorem</h4><h5 id="Definition-6"><a href="#Definition-6" class="headerlink" title="Definition"></a>Definition</h5><ul>
<li><strong>Cooperative equilibria which do not exist in static games can be achieved in repeated games.</strong></li>
</ul>
<h5 id="Friedman-Theorem"><a href="#Friedman-Theorem" class="headerlink" title="Friedman Theorem"></a>Friedman Theorem</h5><ul>
<li><p>Feasible Payoff</p>
<ul>
<li>The payoffs $(x_1 , . . . , x_n)$ are feasible in the stage game G if they are a convex combination （i.e., a weighted average, where the weights are all nonnegative and sum to one） of the pure-strategy payoffs of G.</li>
<li><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230403152406.png" alt="feasible payoff"></li>
</ul>
</li>
<li><p>Average Payoff</p>
<ul>
<li>Given the discount factor $\delta$, the average payoff of the infinite sequence of payoffs $\pi_1, \pi_2, . . .$ is</li>
<li>$$(1-\delta )\sum_{i&#x3D;1}^\infty \delta^{(t-1)}\pi_t$$</li>
<li>Both present value and average payoff can present a player’s payoff in an infinitely repeated game. </li>
<li>Average payoff is directly comparable to the payoffs from the stage game.</li>
</ul>
</li>
<li><p><strong>Friedman Theorem</strong></p>
<ul>
<li>Let G be a finite, static game of complete information. Let $(e_1,…,e_n)$ denote the payoffs from a Nash equilibrium of G, and let $(x_1,…, x_n)$ denote any feasible payoffs from G, where $x_i &gt; e_i$ for each player i. If the discount factor $\delta$ is suiciently close to one, then there exists a subgame-perfect Nash equilibrium in the infinitely repeated game G( ∞, δ) that achieves $(x_1,…, x_n)$ as the average payoff.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="L5-Static-games-with-incomplete-information"><a href="#L5-Static-games-with-incomplete-information" class="headerlink" title="L5:Static games with incomplete information"></a>L5:Static games with incomplete information</h2><h3 id="Intro-1"><a href="#Intro-1" class="headerlink" title="Intro"></a>Intro</h3><ul>
<li>games of complete information, i.e., each player’s payoff function is common knowledge among all players. </li>
<li>In the auction example, each player’s payoff function is no longer common knowledge:<ul>
<li>Buyer i’s payof function contains private information, which is not known by other buyers. </li>
<li>This is an example of incomplete information games （不完全信息博弈）, in which at least one player is uncertain about another player’s payoff function.</li>
</ul>
</li>
<li>Games of incomplete information are also called Bayesian games （贝叶斯博弈）<ul>
<li>Two types of Bayesian games: static vs. dynamic.</li>
</ul>
</li>
</ul>
<h4 id="Cournot-Competition-under-Asymmetric-Information"><a href="#Cournot-Competition-under-Asymmetric-Information" class="headerlink" title="Cournot Competition under Asymmetric Information"></a>Cournot Competition under Asymmetric Information</h4><ul>
<li>类似与原本的古诺模型，但是现在firm2的成本 $c_2$ 有 $\theta$ 的可能性是 $c_H$ , 有 $1-\theta$ 的可能性是 $c_L$ </li>
<li>因此，信息不对称：<ul>
<li>Firm 1’s cost function is known by both firms.<ul>
<li>$c_1$ is common knowledge.</li>
</ul>
</li>
<li>Firm 2’s cost function is completely known by itself, but not known by firm 1.<ul>
<li>$c_2$ is not common knowledge.</li>
</ul>
</li>
<li>Firm 1 only knows the distribution of firm 2’s marginal cost</li>
</ul>
</li>
<li>自然，firm 2会对于不同的成本选择不同的生产量</li>
<li>firm 1 应该合理预期这种差异</li>
<li>Let $q_2^*(c_H)$ and $q_2^*(c_L)$ denote firm 2’s quantity choices when its marginal cost is $c_H$ and $c_L$ respectively, and let $q^∗_1$ denote firm 1’s single choice of quantity.</li>
<li>If firm 2’s cost is $c_j (j &#x3D; L, H)$, it will choose $q^∗_2(c_j)$ to solve<ul>
<li>$$\max_{q_2}(a-q1^*-q_2-c_j)q_2$$</li>
</ul>
</li>
<li>firm 1 chooses $q^∗_1$ to solve<ul>
<li>$$\max_{q_1}\theta(a-q_2^*(c_H)-q_1-c)q_1+(1-\theta)(a-q_2^*(c_L)-q_1-c)q_1$$</li>
</ul>
</li>
<li>一阶导数：<ul>
<li>$$q_2^*(c_H) &#x3D;\frac{a-q_1^*-c_H}{2}$$</li>
<li>$$q_2^*(c_L)&#x3D;\frac{a-q_1^*-c_L}{2}$$</li>
<li>$$q_1^* &#x3D;\frac{a-\theta q_2^*(c_H)-(1-\theta) q_2^*(c_L)-c}{2}$$</li>
</ul>
</li>
<li>The <strong>equilibrium</strong> of this game is $\left(q_1^*,\left(q_2^<em>\left(c_H\right), q_2^</em>\left(c_L\right)\right)\right)$, where<ul>
<li>$$q_1^* &#x3D;\frac{a-2 c+\theta c_H+(1-\theta) c_L}{3}$$</li>
<li>$$q_2^*(c_H) &#x3D;\frac{a-2 c_H+c}{3}+\frac{1-\theta}{6}\left(c_H-c_L\right)$$</li>
<li>$$q_2^*(c_L)&#x3D;\frac{a-2 c_L+c}{3}-\frac{\theta}{6}(c_H-c_L)$$</li>
</ul>
</li>
</ul>
<ul>
<li>We know $q_2^*(c_H)&lt;q_2^*(c_L) \Rightarrow$ firm 2 produces less when its marginal cost increases.</li>
</ul>
<ul>
<li>Firm 2 knows firm 1’s payoff function, while firm 1 does not know firm 2’s payoff functions but only knows the probability distribution. </li>
<li>This is Bayesian game.</li>
</ul>
<h3 id="Static-Bayesian-games"><a href="#Static-Bayesian-games" class="headerlink" title="Static Bayesian games"></a>Static Bayesian games</h3><ul>
<li>Consider a general static Bayesian game.<ul>
<li>Let player $i$ ‘s possible payoff function be $u_i\left(a_1, \ldots, a_n ; t_i\right)$, where $a_i$ is player $i$ ‘s action and $t_i$ is called player $i$ ‘s type （类型）, which belongs to a set of possible types $T_i$ （or type spaces）.</li>
<li>Player $i$ ‘s type $t_i$ is his private information, and each type $t_i$ corresponds to a different payoff function of player $i$.</li>
<li>Let $t_{-i}&#x3D;\left(t_1, \ldots, t_{i-1}, t_{i+1}, \ldots, t_n\right)$ be the types of other players and $T_{-i}$ be the set of all $t_{-i}$.</li>
<li>Player $i$ is uncertain about other players’ types, but only knows the probability distribution $p_i\left(t_{-i} \mid t_i\right)$ on $T_{-i}$, which is i’s belief （猜测&#x2F;估计&#x2F;信念） about other players’ types, given i’s knowledge of his own $t_i$.</li>
</ul>
</li>
</ul>
<h5 id="Definition-7"><a href="#Definition-7" class="headerlink" title="Definition"></a>Definition</h5><ul>
<li>The normal-form (标准式) representation of an $n$-player static Bayesian game specifies players’<br>(1) action spaces $A_1, \ldots, A_n$,<br>(2) type spaces $T_1, \ldots, T_n$,<br>(4) payoff functions $u_1, \ldots, u_n$.</li>
<li>We denote this game by<br>$$<br>G&#x3D;\left\langle A_1, \ldots, A_n ; T_1, \ldots, T_n ; p_1, \ldots, p_n ; u_1, \ldots, u_n\right\rangle<br>$$</li>
</ul>
<h5 id="Example-2"><a href="#Example-2" class="headerlink" title="Example"></a>Example</h5><ul>
<li>In the Cournot game with asymmetric information,<ul>
<li>$A_{\ell}&#x3D;A_2&#x3D;[0, \infty)$</li>
<li>$T_1&#x3D;{c}$, and $T_2&#x3D;{c_H, c_L}$<ul>
<li>至少是singleton</li>
</ul>
</li>
<li>$p_1\left(c_H \mid c\right)&#x3D;\theta, p_1\left(c_L \mid c\right)&#x3D;1-\theta$, and $p_2\left(c \mid c_H\right)&#x3D;p_2\left(c \mid c_L\right)&#x3D;1$</li>
<li>Payoff functions are<br>$$<br>\begin{aligned}<br>\pi_1\left(q_1, q_2 ; c\right) &amp; &#x3D;\left(a-q_1-q_2-c\right) q_1 \\<br>\pi_2\left(q_1, q_2 ; c_L\right) &amp; &#x3D;\left(a-q_1-q_2-c_L\right) q_2 \\<br>\pi_2\left(q_1, q_2 ; c_H\right) &amp; &#x3D;\left(a-q_1-q_2-c_H\right) q_2<br>\end{aligned}<br>$$</li>
</ul>
</li>
</ul>
<h5 id="timing"><a href="#timing" class="headerlink" title="timing"></a>timing</h5><ul>
<li>The timing of a static Bayesian game:<ol>
<li>Nature draws a type vector $t &#x3D; (t_1 ,…, t_n)$, where $t_i ∈ T_i$ ;</li>
<li>Nature reveals $t_i$ to player i, but not to any other players;</li>
<li>The players simultaneously choose actions, player i choosing $a_i ∈ A_i$; </li>
<li>Payoffs $u_i (a_1 ,…, a_n;t_i)$ are received.</li>
</ol>
</li>
<li>By introducing the frictional moves by nature in 1 and 2, we have described a game of incomplete information as a game of imperfect information.</li>
</ul>
<h5 id="Bayes’-rule"><a href="#Bayes’-rule" class="headerlink" title="Bayes’ rule"></a>Bayes’ rule</h5><ul>
<li>We often assume that the nature draws $t&#x3D;\left(t_1, \ldots, t_n\right)$ according to the prior probability distribution $p(t)$ （先验概率分布&#x2F;事前概率分布）, which is common knowledge.</li>
</ul>
<ul>
<li>Then the posterior belief $p_i\left(t_{-i} \mid t_i\right)$ can be computed by Bayes’ rule 贝叶斯公式<br>$$<br>p_i\left(t_{-i} \mid t_i\right)&#x3D;\frac{p\left(t_{-i}, t_i\right)}{\sum_{t_{-i}^{\prime} \in T_{-i}} p\left(t_{-i}^{\prime}, t_i\right)} .<br>$$</li>
</ul>
<h5 id="Remarks"><a href="#Remarks" class="headerlink" title="Remarks"></a>Remarks</h5><ul>
<li>First, there are games in which player i has private information not only about his or her own payoff function but also about another player’s payoff function. We write player i’s payoff function as $u_i (a_1 , . . . , a_n; t_1, . . . , t_n)$. （interdependent （相互决定））</li>
<li>Second, we typically assume that players’ types are independent （otherwise, correlated）, i.e., $p_i(t_{−i} |t_i)$ does not depend on $t_i$, which can be denoted by $p_i(t_{−i})$. But $p_i(t_{−i})$ is still derived from the prior distribution $p(t)$.</li>
</ul>
<h4 id="Strategy-and-Bayesian-Nash-equilibrium"><a href="#Strategy-and-Bayesian-Nash-equilibrium" class="headerlink" title="Strategy and Bayesian Nash equilibrium"></a>Strategy and Bayesian Nash equilibrium</h4><ul>
<li>In the static Bayesian game $G &#x3D; ⟨A_1 , . . . , A_n; T_1, . . . , T_n; p_1, . . . , p_n; u_1, . . . , u_n⟩$, a strategy for player i is a function $s_i(t_i)$, i.e., $s_i: T_i → A_i$. For given type $t_i$, $s_i(t_i)$ gives an action of player i. Player i’s strategy space $S_i$ is the set of all functions from $T_i$ into $A_i$.</li>
<li>在上例中，$(q^*_2(c_H),q^*_2(c_L))$ 是player 2 的一个策略，$q^*_1$ 是player 1 的一个策略</li>
</ul>
<h5 id="Definition-8"><a href="#Definition-8" class="headerlink" title="Definition"></a>Definition</h5><ul>
<li>In the static Bayesian game</li>
<li>$G&#x3D;\langle A_1, \ldots, A_n ; T_1, \ldots, T_n ; p_1, \ldots, p_n ; u_1, \ldots, u_n\rangle$, the strategy profile $s^*&#x3D;(s_1^*, \ldots, s_n^*)$ are a （pure-strategy） Bayesian Nash equilibrium （贝叶斯-纳什均衡） if for each player $i$ and for each of $i$ ‘s types $t_i \in T_i, s_i^*\left(t_i\right)$ solves</li>
<li>$$\max <em>{a_i \in A_i} \sum</em>{t_{-i} \in T_{-i}} u_i(s_{-i}^*(t_{-i}), a_i ; t_i) \cdot p_i(t_{-i} \mid t_i) .$$</li>
<li>先验分布下不同情况的收益加权。</li>
</ul>
<ul>
<li>In a general finite static Bayesian game （finite players, finite actions, and finite types）, a Bayesian Nash equilibrium exists, perhaps in mixed strategies.</li>
</ul>
<ul>
<li>In a Bayesian Nash equilibrium, each player’s strategy is a best response to other players’ strategies. </li>
<li>In other words, no player wants to change his or her strategy unilaterally given other players’ equilibrium strategies, even if the change involves only one action by one type. </li>
<li>A Bayesian Nash equilibrium is simply a Nash equilibrium in a Bayesian game.</li>
</ul>
<h3 id="Application-1"><a href="#Application-1" class="headerlink" title="Application"></a>Application</h3><h4 id="A-trading-game"><a href="#A-trading-game" class="headerlink" title="A trading game"></a>A trading game</h4><ul>
<li>可以把带有概率的game转化成多个人，每个人代表一种possibility</li>
<li><img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230403194427.png" alt="extensive form of the game"></li>
<li>Normal-form representation of the game:<ul>
<li>Action spaces: A1 &#x3D; {B, N} and A2 &#x3D; {P, N};</li>
<li>Type spaces: T1 &#x3D; {10, 14} and T2 &#x3D; {1};</li>
<li>Beliefs:the buyer’s belief on the seller’s type is 1 on type 1, the seller’s belief on the buyer’s types is 2&#x2F;3 on 10 and 1&#x2F;3 on 14;</li>
<li>Payoffs are given as above.</li>
</ul>
</li>
<li>Strategy spaces: S1 &#x3D; {BB, BN, NB, NN} and S2 &#x3D; {P, N} <ul>
<li>The meaning of BN: the buyer with outside option 10 chooses “to buy” and with outside option 14 chooses “not to buy”.</li>
</ul>
</li>
<li>可以用bi-matrix来表示这个状态，找到best response</li>
</ul>
<h4 id="Mixed-strategies-revisited"><a href="#Mixed-strategies-revisited" class="headerlink" title="Mixed strategies revisited"></a>Mixed strategies revisited</h4><ul>
<li><p>考虑 battle of sexes</p>
</li>
<li><p>Suppose the couple are uncertain about the payoffs for each other</p>
</li>
<li><table>
<thead>
<tr>
<th align="right"></th>
<th align="center">Opera</th>
<th align="center">Football</th>
</tr>
</thead>
<tbody><tr>
<td align="right"><strong>Opera</strong></td>
<td align="center">1，2+$t_w$</td>
<td align="center">0,0</td>
</tr>
<tr>
<td align="right"><strong>Football</strong></td>
<td align="center">0,0</td>
<td align="center">2+$t_h$, 1</td>
</tr>
</tbody></table>
</li>
<li><p>Here $t_w$ is privately known by the wife, while $t_h$ is privately known by the husband. </p>
</li>
<li><p>Assume that $t_w$ and $t_h$ are independently drawn from a uniform distribution on $[0, x]$, where x &gt; 0.</p>
</li>
<li><p>The normal-form representation of this static Bayesian game is $G&#x3D;\left\langle A_h, A_w ; T_h, T_p ; p_h, p_w ; u_h, u_w\right\rangle$ :</p>
<ul>
<li>$A_h&#x3D;A_w&#x3D;{ \text{Opera, Football} }$;</li>
<li>$T_h&#x3D;T_w&#x3D;[0, x]$</li>
<li>The husband believes that $t_w$ （the wife believes that $t_h$ ） is uniformly distributed on $[0, x]$;</li>
<li>$u_h$ and $u_w$ are given before.</li>
</ul>
</li>
</ul>
<ul>
<li>构造两个 critical value, $\bar{t_w}$ 和 $\bar{t_h}$ <ul>
<li>In the Bayesian Nash equilibrium, the husband will choose Football if $t_h$ exceeds the critical value $\bar{t_h}$, and choose Opera otherwise.</li>
<li>老婆同理</li>
</ul>
</li>
</ul>
<h5 id="解"><a href="#解" class="headerlink" title="解"></a>解</h5><ul>
<li>Given the wife’s strategy, the husband’s expected payoffs of choosing Opera and Football are<br>$$<br>\begin{aligned}<br>u_h\left(\text { Opera, } s_w^* \mid t_h\right) &amp; &#x3D;\operatorname{Pr}\left(s_w^*&#x3D;\text { Opera }\right) \cdot 1+\operatorname{Pr}\left(s_w^*&#x3D;\text { Football }\right) \cdot 0 \\<br>&amp; &#x3D;\left(1-\frac{\bar{t}_w}{x}\right) \cdot 1+\frac{\bar{t}_w}{x} \cdot 0&#x3D;1-\frac{\bar{t}_w}{x},<br>\end{aligned}<br>$$<br>and<br>$$<br>u_h\left(\text { Football, } s_w^* \mid t_h\right)&#x3D;\left(1-\frac{\bar{t}_w}{x}\right) \cdot 0+\frac{\bar{t}_w}{x} \cdot\left(2+t_h\right)&#x3D;\frac{\bar{t}_w}{x}\left(2+t_h\right) .<br>$$</li>
<li>Thus, choosing Opera is optimal iff<br>$$<br>1-\frac{\bar{t}_w}{x} \geq \frac{\bar{t}_w}{x}\left(2+t_h\right) \Longleftrightarrow t_h \leq \frac{x}{\bar{t}_w}-3&#x3D;\bar{t}_h .<br>$$</li>
</ul>
<ul>
<li>wife 同理</li>
<li>$$1-\frac{\bar{t}_h}{x} \geq \frac{\overline{\bar{t}}_h}{x}\left(2+t_w\right) \Longleftrightarrow t_w \leq \frac{x}{\bar{t}_h}-3&#x3D;\bar{t}_w .$$</li>
<li>Solving simultaneously, we obtain $\bar{t}_h$ and $\bar{t}_w$ satisfy<br>$$<br>t^2+3 t-x&#x3D;0 .<br>$$</li>
</ul>
<ul>
<li>Thus, $\bar{t}_h&#x3D;\bar{t}_w&#x3D;\frac{\sqrt{9+4 x}-3}{2}$.</li>
<li>In equilibrium, the husband plays Opera with probability $p^*$ and Football with probability $1-p^*$, while the wife plays Football with probability $p^*$ and Opera with probability $1-p^*$, where<br>$$<br>p^*&#x3D;\frac{\bar{t}_h}{x}&#x3D;\frac{\bar{t}_w}{x}&#x3D;\frac{2}{\sqrt{9+4 x+3}} .<br>$$</li>
<li>When $x \rightarrow 0$, we get that $p^* \rightarrow \frac{1}{3}$.</li>
<li>As the incomplete information disappears, the players’ behavior in this pure-strategy Bayesian Nash equilibrium approaches their behavior in the mixed-strategy Nash equilibrium in the original game of complete information.</li>
</ul>
<hr>
<h2 id="L6-Auction"><a href="#L6-Auction" class="headerlink" title="L6: Auction"></a>L6: Auction</h2><h3 id="Intro-2"><a href="#Intro-2" class="headerlink" title="Intro"></a>Intro</h3><ul>
<li>An auction is a mechanism of allocating goods.<ul>
<li>Analyze bidders’ behaviors.</li>
<li>Analyze auctioneer’s “optimal” choice.</li>
</ul>
</li>
<li>Advantages of auctions:<ul>
<li>a simple way of determining the market-based prices; </li>
<li>more flexible than setting a fixed price; </li>
<li>can usually achieve eiciency by allocating the resources to those who value them most highly.</li>
</ul>
</li>
</ul>
<h4 id="Types-of-auctions"><a href="#Types-of-auctions" class="headerlink" title="Types of auctions"></a>Types of auctions</h4><ul>
<li>Number of objects<ul>
<li>A single object or many?</li>
</ul>
</li>
<li>Open vs. sealed-bid<ul>
<li>Do you know the bids of other participants?</li>
</ul>
</li>
<li>One-sided vs. two-sided<ul>
<li>Do buyers and sellers both submit bids, or just buyers?</li>
</ul>
</li>
<li>Private value vs. common value<ul>
<li>Do the bidders have the same valuation for the object?</li>
</ul>
</li>
</ul>
<h3 id="Second-price-auction"><a href="#Second-price-auction" class="headerlink" title="Second-price auction"></a>Second-price auction</h3><ul>
<li>每个人的心理预期是从一个分布中随机的，$F_i(·)$</li>
<li>每个人都只知道自己的心理预期但不知道别人的</li>
<li>所有人同时竞价</li>
<li>出价最高者赢得物品，并支付第二高价格</li>
<li>如果同时好几个人出价最高，则随机给到一个人</li>
</ul>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><ul>
<li>For each player i, the strategy of bidding his valuation （i.e., $s^∗_i(v_i) &#x3D; v_i$ ）weakly dominates all other strategies.<ul>
<li>分别考虑报价更低与更高，都是 weakly dominates</li>
</ul>
</li>
</ul>
<h3 id="First-price-auction"><a href="#First-price-auction" class="headerlink" title="First-price auction"></a>First-price auction</h3><ul>
<li><p>两个bidder，valuation在（0，1）上服从uniform distribution</p>
</li>
<li><p>只知道自己的valuation</p>
</li>
<li><p>同时bid</p>
</li>
<li><p>出价高者得，出价低者不用出钱</p>
</li>
<li><p>出价相同，随机获得</p>
</li>
<li><p>Normal-form representation of this static Bayesian game $G&#x3D;\left\langle A_1, A_2 ; T_1, T_2 ; p_1, p_2 ; u_1, u_2\right\rangle$</p>
<ul>
<li>$A_1&#x3D;A_2&#x3D;[0, \infty)$, and each bid is $b_i \in A_i$;</li>
<li>$T_1&#x3D;T_2&#x3D;[0,1]$, and each valuation is $v_i \in T_i$;</li>
<li>Player $i$ believes that $v_j$ is uniformly distributed on $[0,1]$;</li>
<li>The payoff $u_i\left(b_i, b_j ; v_i\right)$ is</li>
<li>$$u_i(b_i, b_j ; v_i)&#x3D; \begin{cases}v_i-b_i, &amp; \text { if } b_i&gt;b_j \\ \frac{1}{2}(v_i-b_i), &amp; \text { if } b_i&#x3D;b_j \\ 0, &amp; \text { if } b_i&lt;b_j\end{cases}$$</li>
</ul>
</li>
</ul>
<ul>
<li>Bidder $i$ ‘s strategy is a function $b_i(v_i)$ from $[0,1]$ to $[0, \infty)$.</li>
<li>$(b_1^*(v_1), b_2^*(v_2))$ is a Bayesian Nash equilibrium if and only if for each player $i$ and each type $v_i \in[0,1], b_i^*\left(v_i\right)$ solves</li>
<li>$$\begin{aligned}<br>&amp; \max <em>{b_i \geq 0} \mathbf{E}</em>{v_j} u_i(b_i, b_j^*(v_j) ; v_i) \\<br>&#x3D; &amp; \max _{b_i \geq 0}{eft(v_i-b_i) \operatorname{Prob}[b_i&gt;b_j^*(v_j)]+\frac{v_i-b_i}{2} \operatorname{Prob}[b_i&#x3D;b_j^*(v_j)]} .<br>\end{aligned}$$</li>
</ul>
<h4 id="Linear-Bayesian-NE"><a href="#Linear-Bayesian-NE" class="headerlink" title="Linear Bayesian NE"></a>Linear Bayesian NE</h4><ul>
<li>可能会有许多纳什均衡，现在只考虑线性情况<ul>
<li>$b^*_1(v_1)&#x3D;a_1+c_1v_1$ , $b^*_2(v_2)&#x3D;a_2+c_2v_2$</li>
</ul>
</li>
<li>需要找到对应的a和c</li>
<li>理性：<ul>
<li>a小于1，不然收益永远为负</li>
<li>c大于等于0，随着valuation上升，出价也上升</li>
<li>a大于等于0，出价不能为负</li>
</ul>
</li>
<li>当 $b_j$ 是线性的时候，$Prob(b_i&#x3D;a_j+c_jv_j)&#x3D;Prob(v_j&#x3D;\frac{b_i-a_j}{c_j})&#x3D;0$ </li>
<li>对于任意的v，需要</li>
<li>$$\max_{b_i\geq 0}(v_i-b_i)Prob(v_j&lt;\frac{b_i-a_j}{c_j})$$</li>
</ul>
<ul>
<li>Since $b_j^*\left(v_j\right)&#x3D;a_j+c_j v_j \in\left[a_j, a_j+c_j\right]$, we can restrict our attention to $b_i \in\left[a_j, a_j+c_j\right]$ <ul>
<li>i.e., $b_i&lt;a_j$ is pointless, while $b_i&gt;a_j+c_j$ is not rational</li>
</ul>
</li>
<li>Under the above restriction, we know<br>$$<br>0 \leq \frac{b_i-a_j}{c_j} \leq 1<br>$$</li>
<li>Player $i$ s best response solves<br>$$<br>\max _{a_j \leq b_i \leq a_j+c_j}\left(v_i-b_i\right) \frac{b_i-a_j}{c_j}<br>$$</li>
</ul>
<ul>
<li>FOC implies the potentially optimal choice is $b_i^o&#x3D;\frac{v_i+a_j}{2}$.<ul>
<li>即求导</li>
</ul>
</li>
</ul>
<ul>
<li>It is the optimal choice iff $b_i^o&#x3D;\frac{v_i+a_j}{2} \in\left[a_j, a_j+c_j\right]$ <ul>
<li>即 $a_j \leq v_i \leq a_j+2 c_j$.</li>
</ul>
</li>
<li>The best response function of bidder $i$ is<br>$$<br>b_i\left(v_i\right)&#x3D; \begin{cases}a_j, &amp; \text { if } v_i \leq a_j \\ \frac{1}{2}\left(v_i+a_j\right), &amp; \text { if } a_j&lt;v_i \leq a_j+2 c_j \\ a_j+c_j, &amp; \text { if } v_i&gt;a_j+2 c_j .\end{cases}<br>$$</li>
</ul>
<ul>
<li>We want the equilibrium bid $b_i\left(v_i\right)$ to be a linear function on $[0,1]$.</li>
</ul>
<ul>
<li>There are three cases:</li>
<li>$$[0,1] \subseteq{\begin{array}{l}<br>(-\infty, a_j] \\<br>{[a_j, a_j+2 c_j]} \\<br>{[a_j+2 c_j, \infty)}<br>\end{array}.$$<ul>
<li>第一种情况不满足a小于1</li>
<li>第三种情况不满足c大于0</li>
<li>因此只能是第二种情况，$b_i&#x3D;\frac{v_i+a_j}{2}$</li>
</ul>
</li>
</ul>
<ul>
<li>In a Bayesian Nash equilibrium,$$b_i^*\left(v_i\right)&#x3D;a_i+c_i v_i&#x3D;\frac{1}{2}\left(v_i+a_j\right)$$for all $v_i \in[0,1]$.</li>
</ul>
<ul>
<li>Then we have$$a_i&#x3D;\frac{1}{2} a_j, \text { and } c_i&#x3D;\frac{1}{2}$$for $i, j&#x3D;1,2$ and $i \neq j$.</li>
<li>Therefore,<br>$$<br>a_1&#x3D;a_2&#x3D;0, \text { and } c_1&#x3D;c_2&#x3D;\frac{1}{2} .<br>$$</li>
<li>The unique linear Bayesian Nash equilibrium is$$b_1^*(v_1)&#x3D;\frac{1}{2} v_1, \text { and } b_2^*(v_2)&#x3D;\frac{1}{2} v_2$$</li>
</ul>
<ul>
<li><strong>如果能直接猜出这个解，就可以直接验证。</strong></li>
</ul>

            </div>
            <hr />

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">随缘买咖啡～</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <div id="wechat">
                        <img src="/medias/reward/Wechat_yyc.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>转载规则</span>
        </p>
        
            <div class="center-align">
                <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《博弈论与机制设计笔记（更新中）》
                </span> 由
            <a xmlns:cc="http://creativecommons.org/ns#" href="/2023/03/17/bo-yi-lun-yu-ji-zhi-she-ji-bi-ji-geng-xin-zhong/" property="cc:attributionName"
               rel="cc:attributionURL">
                Frank Yu
            </a> 采用
            <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                知识共享署名 4.0 国际许可协议
            </a>进行许可。
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    

    

    

    
    <div class="livere-card card" data-aos="fade-up">
    <!-- 来必力City版安装代码 -->
    <div id="lv-container" class="card-content" data-id="city" data-uid="MTAyMC81ODE5NC8zNDY1Nw">
        <script type="text/javascript">
            (function (d, s) {
                let j, e = d.getElementsByTagName(s)[0];
                if (typeof LivereTower === 'function') {
                    return;
                }

                j = d.createElement(s);
                j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
                j.async = true;

                e.parentNode.insertBefore(j, e);
            })(document, 'script');
        </script>
        <noscript>为正常使用来必力评论功能请激活JavaScript。</noscript>
    </div>
    <!-- City版安装代码已完成 -->
</div>
    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2023/03/19/gong-si-jin-rong-bi-ji/">
                    <div class="card-image">
                        
                        <img src="https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230319203730.png" class="responsive-img" alt="公司金融笔记">
                        
                        <span class="card-title">公司金融笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            复习，重看公司金融课件，记录笔记。
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2023-03-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Learning/" class="post-category" target="_blank">
                                    Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Finance/" target="_blank">
                        <span class="chip bg-color">Finance</span>
                    </a>
                    
                    <a href="/tags/Notes/" target="_blank">
                        <span class="chip bg-color">Notes</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2023/03/16/mnist-classification-with-mlp/">
                    <div class="card-image">
                        
                        <img src="https://s2.loli.net/2023/03/11/8nTKz7lUIEvLPSg.png" class="responsive-img" alt="MNIST Classification with MLP">
                        
                        <span class="card-title">MNIST Classification with MLP</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            

	
    
	



                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2023-03-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Learning/" class="post-category" target="_blank">
                                    Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/MachineLearning/" target="_blank">
                        <span class="chip bg-color">MachineLearning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: Frank's Blog<br />'
            + '作者: Frank Yu<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () { bodyElement.removeChild(newdiv); }, 200);
    });
</script>

    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4, h5, h6'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4, h5, h6').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>
<!-- 代码语言 -->
<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>
<!-- 代码块复制 -->
<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>
<script type="text/javascript" src="/libs/codeBlock/clipboard.min.js"></script>
<!-- 代码块收缩 -->
<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script> 
<!-- 代码块折行 -->
<style type="text/css">code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }</style>


    <footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            &copy; 2023-2023 Yu YuChen 版权所有

            
            &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
            <span class="white-color">46.8k</span>
            

            <br>
            <span id="sitetime"></span>

            
            
            <br>
            
            <span id="busuanzi_container_site_pv" style='display:none'>
                <i class="fa fa-heart-o"></i>
                本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
            <span id="busuanzi_container_site_uv" style='display:none'>
                人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
            </span>
            
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ldvyyc" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:yu-yc20@mails.tsinghua.edu.cn" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="https://zhihu.com/people/ldvyyc" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50">
        <i class="fa fa-inverse">知</i>
    </a>



    <a href="http://wpa.qq.com/msgrd?v=3&uin=2992197817&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>





    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>

<!-- 不蒜子计数初始值纠正 -->
<script>
    $(document).ready(function () {

        var int = setInterval(fixCount, 50);
        var pvcountOffset = 80000;
        var uvcountOffset = 20000;

        function fixCount() {
            if (document.getElementById("busuanzi_container_site_pv").style.display != "none") {
                $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()));
                clearInterval(int);
            }
            if ($("#busuanzi_container_site_pv").css("display") != "none") {
                $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())); // 加上初始数据 
                clearInterval(int);
            }
        }
    });
</script>

<script language=javascript>
    function siteTime() {
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth() + 1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();
        /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
        year - 作为date对象的年份，为4位年份值
        month - 0-11之间的整数，做为date对象的月份
        day - 1-31之间的整数，做为date对象的天数
        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
        minutes - 0-59之间的整数，做为date对象的分钟数
        seconds - 0-59之间的整数，做为date对象的秒数
        microseconds - 0-999之间的整数，做为date对象的毫秒数 */
        var t1 = Date.UTC(2023, 03, 10, 00, 00, 00); //北京时间2018-2-13 00:00:00
        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
        var diff = t2 - t1;
        var diffYears = Math.floor(diff / years);
        var diffDays = Math.floor((diff / days) - diffYears * 365);
        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes);
        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds);
        document.getElementById("sitetime").innerHTML = "本站已运行 " + diffYears + " 年 " + diffDays + " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
</script>

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <script type="text/javascript"> var OriginTitile = document.title, st; document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ喔哟，崩溃啦！", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) })
    </script>

    <!-- Global site tag (gtag.js) - Google Analytics -->



    
    <script src="/libs/others/clicklove.js"></script>
    

    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    <!-- 雪花特效 -->
    

</body>

</html>